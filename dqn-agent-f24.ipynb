{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent\n",
    "#### By: Blessing Akintonde, Garnett Gran "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Project, We will be building a Reinforced Learning Deep Q Network Agent to Successfully Land the Lunar Lander in OpenAI Gym's LunarLander-v2 Environment. We will utilize ____, ____, ____ APIs to accomplish this task. \n",
    "\n",
    "Definitions:\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>OpenAI Gym's LunarLander-v2 Environment</b> is Reinforcement Learning Benchmark that simulates a 2D Lunar Lander Attempting to land safely on the moon. The ability of an RL Agent to learn a control policy for complex sequential decision making tasks is demonstrated within this environment, thus, is the goal of sucessfully configuring an Agent to achieve the best results for this assignment\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>DQN Agent: Deep Q Network Agent</b> is an AI System that utilizes Reinforcement Learning Principles with Neural Networks to lern ideal actions in an evnironment to maximize cumulative rewards (do the correct actions consecutively and learn to keep excelling). \n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a simple DQN epsilon policy network with 4 output neurons (one per possible action).  [Hint: DQN Agents use Epsilon greedy policy]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Discuss the rationale of the activation functions & the loss function used in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "Lorem ipsum dolor sit amet consectetur adipisicing elit. Error id optio animi culpa alias quis, commodi recusandae mollitia! Velit voluptas nesciunt veritatis impedit quia ipsa deserunt doloremque dolorem praesentium magnam, vero eaque eos minus aliquid laborum tempora expedita amet dolore voluptatum eveniet! Optio, excepturi nihil quo, quaerat totam, laborum nam dolorum ad recusandae laudantium qui aliquid beatae. Provident, quos quod. Est amet ipsa laboriosam rerum similique saepe nulla recusandae sint animi dolores! Officiis, adipisci a libero eveniet veritatis voluptatibus ipsum. Id delectus impedit rerum! Nulla animi ducimus, nobis aperiam illo perspiciatis tempora reiciendis optio non voluptate rerum enim ipsam quam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the hyperparameters: (i) the number of iterations, (ii) the number of episodes, (iii) the maximum number of steps, and (iv) the discount factor at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the agent on the LunarLander-v2 environment for a sufficient number of episodes to achieve a satisfactory level of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Analyze the agent's learning progress by plotting relevant performance metrics (e.g., cumulative rewards, episode length) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Discuss the challenges faced during training and potential strategies for further improving the agent's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "Lorem ipsum dolor sit amet, consectetur adipisicing elit. Odit nostrum assumenda repellendus maxime impedit ducimus. At quae maiores quia dolor necessitatibus aperiam reiciendis ullam odio accusamus voluptatem aspernatur ex, minima omnis eum totam eos facere, nobis natus culpa a ab voluptatibus? Voluptatem, esse nesciunt vero aut earum provident est quasi maiores ducimus eligendi beatae suscipit ad, adipisci fuga nam iure. Nobis error eligendi nemo, iure ipsam est doloremque rerum voluptate? Ab impedit ullam cupiditate sunt suscipit quisquam, saepe reprehenderit aliquid eius minus, corrupti ad omnis dolorum cumque beatae dolorem aut reiciendis molestiae consequatur rem iusto. Suscipit veniam reiciendis iste molestiae soluta, provident rerum dolores quia molestias non aliquam sunt consectetur aperiam a nisi! Quasi recusandae voluptates quod aspernatur! Modi, maiores quam? Molestias nisi ducimus, distinctio mollitia officia, recusandae fugit eaque eos, laboriosam maiores commodi non id labore placeat enim sed dicta maxime iusto nihil quis animi. Et quia quisquam nulla?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
